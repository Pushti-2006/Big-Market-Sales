# -*- coding: utf-8 -*-
"""Big market sale.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FmY8I0u-8eMXeua8AkRN6Iu8v3yPv17O

Importing the depnedencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

"""Data collection and analysis"""

# loading the dataset from csv file toa pandas dataframe
big_mart_data=pd.read_csv('/content/big_mart_data.csv')

# first 5 rows of the dataframe
big_mart_data.head()

# number of the datapoints and the features
big_mart_data.shape

# getting some information about the datasrt
big_mart_data.info()

"""Categorical Features
-Item_Identifier   
-Item_Fat_Content
-Item_Type   
-Outlet_Indentifier
-Outlet size
-Outlet_location_type
-Outlet_type
"""

#checking for the missing values
big_mart_data.isnull().sum()

"""Handling the missing values

Mean--> average value  
Mode-->Most repeated value
"""

# mean value of the "item_weight" column
big_mart_data['Item_Weight'].mean()

# filling the missing value int hte "Item_weight" column with the mean value
big_mart_data['Item_Weight'].fillna(big_mart_data['Item_Weight'].mean(), inplace=True)

#checking for the missing values
big_mart_data.isnull().sum()

"""Replacing the missing values int the "Outlet_Size" with mode"""

mode_of_outlet_size=big_mart_data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x:x.mode()[0]))
print(mode_of_outlet_size)

missing_values=big_mart_data['Outlet_Size'].isnull()

print(missing_values)

big_mart_data.loc[missing_values, 'Outlet_Size']=big_mart_data.loc[missing_values, 'Outlet_Type'].apply(lambda x:mode_of_outlet_size[x])

big_mart_data.isnull().sum()

"""Data Analysis"""

# statistical measures of the data
big_mart_data.describe()

"""Numerical Features"""

sns.set()

# Item_Weight
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Weight'])
plt.show()

# Item_Visibility
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Visibility'])
plt.show()

# Item_MRP
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_MRP'])
plt.show()

# Item_Outlet_Sales
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Outlet_Sales'])
plt.show()

# Outlet_Establishment_Year
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Establishment_Year', data=big_mart_data)
plt.show()

# 	Item_Fat_Content
plt.figure(figsize=(6,6))
sns.countplot(x='Item_Fat_Content', data=big_mart_data)
plt.show()

# Item_Type
plt.figure(figsize=(30,6))
sns.countplot(x='Item_Type', data=big_mart_data)
plt.show()

# Outlet_Size
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Size', data=big_mart_data)
plt.show()

"""Data Preprocessing"""

big_mart_data.head()

big_mart_data['Item_Fat_Content'].value_counts()

big_mart_data.replace({'Item_Fat_Content':{'low fat':'Low Fat', 'LF':'Low Fat', 'reg':'Regular'}}, inplace=True)

big_mart_data['Item_Fat_Content'].value_counts()

"""Label Encoding"""

encoder=LabelEncoder()

big_mart_data['Item_Identifier']=encoder.fit_transform(big_mart_data['Item_Identifier'])

big_mart_data['Item_Fat_Content']=encoder.fit_transform(big_mart_data['Item_Fat_Content'])

big_mart_data['Item_Type']=encoder.fit_transform(big_mart_data['Item_Type'])

big_mart_data['Outlet_Identifier']=encoder.fit_transform(big_mart_data['Outlet_Identifier'])

big_mart_data['Outlet_Size']=encoder.fit_transform(big_mart_data['Outlet_Size'])

big_mart_data['Outlet_Location_Type']=encoder.fit_transform(big_mart_data['Outlet_Location_Type'])

big_mart_data['Outlet_Type']=encoder.fit_transform(big_mart_data['Outlet_Type'])

big_mart_data.head()

"""Splitting the features and targets"""

X=big_mart_data.drop(columns='Item_Outlet_Sales', axis=1)
Y=big_mart_data['Item_Outlet_Sales']

"""Splitting the data into training data and testing data"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Machine Learning Model Training"""

regressor=XGBRegressor()

regressor.fit(X_train, Y_train)

"""Evaluation"""

#prediction on training data
trainig_data_prediction=regressor.predict(X_train)

# R squared value
r2_train=metrics.r2_score(Y_train, trainig_data_prediction)

print('R Squared value',r2_train)

# prediction on the test data
test_data_prediction=regressor.predict(X_test)

# R squared value
r2_test=metrics.r2_score(Y_test, test_data_prediction)

print('R Squared value',r2_test)

"""Buiding the Predictive System"""

#  build a predictive system

# The order of features should match the training data X
# X columns: 'Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'
input_data=(6, 10.0, 0, 0.016047300000000002, 9, 112.3184, 1, 1987, 1, 0, 1) # Added a dummy value (0) for 'Item_Fat_Content' and reordered based on X.head() and X.columns
# changing the input data to a numpy array
input_data_as_numpy_array=np.asarray(input_data)
# reshape the array as we are predictiong for one instance
input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)
prediction=regressor.predict(input_data_reshaped)
print(prediction)
print('The item outlet sales is',prediction[0])

